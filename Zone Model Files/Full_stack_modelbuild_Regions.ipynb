{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, GlobalMaxPooling1D, MaxPooling2D, Flatten, Dense, Input, Concatenate, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Closest_State</th>\n",
       "      <th>Closest_City</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10229</td>\n",
       "      <td>i gotta get you readded to bbm</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16439</td>\n",
       "      <td>ahhh yes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17131</td>\n",
       "      <td>an old locksmith</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2648</td>\n",
       "      <td>rt  they are shooting at pentagon metro please...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2750</td>\n",
       "      <td>as a matter of fact i wanna ask about that</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Adamsville</td>\n",
       "      <td>South</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp                                          TweetText Closest_State  \\\n",
       "0      10229                     i gotta get you readded to bbm       Alabama   \n",
       "1      16439                                           ahhh yes       Alabama   \n",
       "2      17131                                   an old locksmith       Alabama   \n",
       "3       2648  rt  they are shooting at pentagon metro please...       Alabama   \n",
       "4       2750         as a matter of fact i wanna ask about that       Alabama   \n",
       "\n",
       "  Closest_City Region  \n",
       "0   Adamsville  South  \n",
       "1   Adamsville  South  \n",
       "2   Adamsville  South  \n",
       "3   Adamsville  South  \n",
       "4   Adamsville  South  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('All_US_tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374519, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['South', 'Southwest', 'West Coast', 'Rockies', 'Northeast',\n",
       "       'Midwest', 'NonCont'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "West_Coast = ('California','Oregon', 'Washington')\n",
    "Southwest = ('Arizona','New Mexico','Oklahoma','Texas')\n",
    "Rockies = ('Nevada','Utah','Colorado','Wyoming','Idaho','Montana')\n",
    "Midwest = ('North Dakota','South Dakota','Nebraska','Kansas','Missouri','Iowa','Minnesota')\n",
    "East_Midwest = ('Wisconsin','Illinois','Indiana','Michigan','Ohio')\n",
    "South = ('Tennessee','Kentucky','North Carolina', 'Virginia','West Virginia','Maryland','Delaware', 'District of Columbia')\n",
    "Deep_South = ('Arkansas','Louisiana','Mississippi','Alabama','Georgia','Florida','South Carolina',)\n",
    "Northeast = ('Pennsylvania','New Jersey','New York','Massachusetts', 'Rhode Island','Conneticut','Vermont','New Hampshire','Maine')\n",
    "NonCont = ('Hawaii','Alaska', 'Puerto Rico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['TweetText'] = df['TweetText'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(df['TweetText'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['Closest_City']\n",
    "df2 = df2.drop(cols, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(df2['Region'])\n",
    "df2 = df2.join(one_hot)\n",
    "df2 = df2.drop('Region', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Closest_State</th>\n",
       "      <th>Midwest</th>\n",
       "      <th>NonCont</th>\n",
       "      <th>Northeast</th>\n",
       "      <th>Rockies</th>\n",
       "      <th>South</th>\n",
       "      <th>Southwest</th>\n",
       "      <th>West Coast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10229</td>\n",
       "      <td>i gotta get you readded to bbm</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16439</td>\n",
       "      <td>ahhh yes</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17131</td>\n",
       "      <td>an old locksmith</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2648</td>\n",
       "      <td>rt  they are shooting at pentagon metro please...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2750</td>\n",
       "      <td>as a matter of fact i wanna ask about that</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp                                          TweetText Closest_State  \\\n",
       "0      10229                     i gotta get you readded to bbm       Alabama   \n",
       "1      16439                                           ahhh yes       Alabama   \n",
       "2      17131                                   an old locksmith       Alabama   \n",
       "3       2648  rt  they are shooting at pentagon metro please...       Alabama   \n",
       "4       2750         as a matter of fact i wanna ask about that       Alabama   \n",
       "\n",
       "   Midwest  NonCont  Northeast  Rockies  South  Southwest  West Coast  \n",
       "0        0        0          0        0      1          0           0  \n",
       "1        0        0          0        0      1          0           0  \n",
       "2        0        0          0        0      1          0           0  \n",
       "3        0        0          0        0      1          0           0  \n",
       "4        0        0          0        0      1          0           0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dat = df2[['TweetText','Timestamp']]\n",
    "y_dat = df2[df['Region'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_dat, y_dat, test_size = 0.25, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    374519.000000\n",
       "mean         11.836540\n",
       "std           7.578886\n",
       "min           1.000000\n",
       "1%            2.000000\n",
       "50%          10.000000\n",
       "99%          29.000000\n",
       "max         710.000000\n",
       "Name: TweetText, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_dat[\"TweetText\"].str.split(\" \").str.len().describe(percentiles=[0.01, 0.5, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_length = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(x_train['TweetText'].tolist())\n",
    "test_sequences = tokenizer.texts_to_sequences(x_test['TweetText'].tolist())\n",
    "\n",
    "train_seq = pad_sequences(train_sequences, maxlen = tmax_length, padding = 'post', truncating = 'post')\n",
    "test_seq = pad_sequences(test_sequences, maxlen = tmax_length, padding = 'post', truncating = 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.index_word) + 1\n",
    "embedding_dim = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_train = x_train['Timestamp']\n",
    "timestamps_test = x_test['Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Input Sequence (InputLayer)     [(None, 29)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 29, 150)      27806850    Input Sequence[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 27, 128)      57728       embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Input Timestamp (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 129)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 Input Timestamp[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 50)           6500        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 25)           1275        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 15)           390         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7)            112         dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 27,872,855\n",
      "Trainable params: 27,872,855\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_seq = Input(shape = (tmax_length,), name = 'Input Sequence')\n",
    "input_time = Input(shape = (1,), name = \"Input Timestamp\")\n",
    "\n",
    "embed = Embedding(input_dim = vocab_size, output_dim = embedding_dim, input_length = tmax_length)(input_seq)\n",
    "convol = Conv1D(filters = 128, kernel_size = 3, activation = 'relu')(embed)\n",
    "maxpool = GlobalAveragePooling1D()(convol)\n",
    "\n",
    "concat = Concatenate()([maxpool, input_time])\n",
    "dense1 = Dense(50, activation = 'relu')(concat)\n",
    "dense2 = Dense(25, activation = 'relu')(dense1)\n",
    "dense3 = Dense(15, activation = 'relu')(dense2)\n",
    "output = Dense(len(df['Region'].unique()), activation = 'sigmoid')(dense3)\n",
    "\n",
    "model = Model(inputs = [input_seq, input_time], outputs = output)\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "#model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1873/1873 [==============================] - 388s 207ms/step - loss: 32.8362 - accuracy: 0.2842 - val_loss: 1.8183 - val_accuracy: 0.3864\n",
      "Epoch 2/5\n",
      "1873/1873 [==============================] - 392s 209ms/step - loss: 1.5711 - accuracy: 0.3865 - val_loss: 1.4672 - val_accuracy: 0.3875\n",
      "Epoch 3/5\n",
      "1873/1873 [==============================] - 409s 218ms/step - loss: 1.4527 - accuracy: 0.3870 - val_loss: 1.4425 - val_accuracy: 0.3876\n",
      "Epoch 4/5\n",
      "1873/1873 [==============================] - 415s 221ms/step - loss: 1.4805 - accuracy: 0.3859 - val_loss: 1.4389 - val_accuracy: 0.3875\n",
      "Epoch 5/5\n",
      "1873/1873 [==============================] - 416s 222ms/step - loss: 1.4682 - accuracy: 0.3863 - val_loss: 1.4379 - val_accuracy: 0.3874\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([train_seq, timestamps_train], y_train, epochs = 5, batch_size = 150, validation_data = ([test_seq, timestamps_test], y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
