{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nicho\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "import pickle\n",
    "\n",
    "from transformers import BertTokenizer, TFBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('All_US_Tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'TweetText', 'Closest_State', 'Closest_City', 'Region'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['South', 'Southwest', 'West Coast', 'Rockies', 'Northeast',\n",
       "       'Midwest', 'NonCont'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "West_Coast = ('California','Oregon', 'Washington')\n",
    "Southwest = ('Arizona','New Mexico','Oklahoma','Texas')\n",
    "Rockies = ('Nevada','Utah','Colorado','Wyoming','Idaho','Montana')\n",
    "Midwest = ('North Dakota','South Dakota','Nebraska','Kansas','Missouri','Iowa','Minnesota','Wisconsin','Illinois',\n",
    "          'Indiana','Michigan','Ohio')\n",
    "South = ('Arkansas','Louisiana','Mississippi','Tennessee','Kentucky','Alabama','Georgia','Florida','South Carolina','North Carolina',\n",
    "        'Virginia','West Virginia','Maryland','Delaware', 'District of Columbia')\n",
    "Northeast = ('Pennsylvania','New Jersey','New York','Massachusetts', 'Rhode Island','Conneticut','Vermont','New Hampshire','Maine')\n",
    "NonCont = ('Hawaii','Alaska', 'Puerto Rico')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROI = NonCont\n",
    "Cap_Per_State = 500\n",
    "out_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfoi = df[df['Closest_State'].isin(ROI)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for state in ROI:\n",
    "    df_s = dfoi[dfoi['Closest_State'] == state]\n",
    "    \n",
    "    if len(df_s) < Cap_Per_State:\n",
    "        sample_state = df_s.sample(n = len(df_s), random_state = 100)\n",
    "    else:\n",
    "        sample_state = df_s.sample(n = Cap_Per_State, random_state = 100)\n",
    "    \n",
    "    out_df = pd.concat([out_df, sample_state], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df['TweetText'] = out_df['TweetText'].astype(str)\n",
    "out_df = out_df[out_df['TweetText'].str.split(\" \").str.len() <= 29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nicho\\anaconda3\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# Bert tools\n",
    "\n",
    "b_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = TFBertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_tweet(tweet):\n",
    "    return b_tokenizer(tweet, padding=True, truncation=True, return_tensors=\"tf\")\n",
    "\n",
    "#tokenized_tweets = df['tweet_text'].apply(tokenize_tweet)\n",
    "\n",
    "def get_bert_embeddings(tokenized_tweet):\n",
    "    outputs = bert_model(tokenized_tweet)\n",
    "    return outputs.last_hidden_state[:, 0, :]\n",
    "    #return outputs[0]\n",
    "\n",
    "#embeddings = tokenized_tweets.apply(get_bert_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df['TweetText'] = out_df['TweetText'].apply(tokenize_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "out_df['TweetText'] = out_df['TweetText'].apply(get_bert_embeddings)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution took: 0.0 hrs, 1.0 min, 10.5secs\n"
     ]
    }
   ],
   "source": [
    "total_time = end - start\n",
    "hours = total_time // 3600\n",
    "mins = total_time % 3600 // 60\n",
    "sec = total_time % 3600 % 60\n",
    "\n",
    "print(\"Execution took: \" + str(hours) + ' hrs, ' + str(mins) + ' min, ' + str(np.round(sec,2)) + 'secs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Closest_State</th>\n",
       "      <th>Closest_City</th>\n",
       "      <th>Region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>46868</td>\n",
       "      <td>((tf.Tensor(-0.7304522, shape=(), dtype=float3...</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Vega Alta</td>\n",
       "      <td>NonCont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32164</td>\n",
       "      <td>((tf.Tensor(-0.29484046, shape=(), dtype=float...</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Vega Alta</td>\n",
       "      <td>NonCont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81417</td>\n",
       "      <td>((tf.Tensor(-0.40089443, shape=(), dtype=float...</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Vega Alta</td>\n",
       "      <td>NonCont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65326</td>\n",
       "      <td>((tf.Tensor(0.07629065, shape=(), dtype=float3...</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Vega Alta</td>\n",
       "      <td>NonCont</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>44303</td>\n",
       "      <td>((tf.Tensor(-0.116008, shape=(), dtype=float32...</td>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>Vega Alta</td>\n",
       "      <td>NonCont</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp                                          TweetText Closest_State  \\\n",
       "0      46868  ((tf.Tensor(-0.7304522, shape=(), dtype=float3...   Puerto Rico   \n",
       "1      32164  ((tf.Tensor(-0.29484046, shape=(), dtype=float...   Puerto Rico   \n",
       "2      81417  ((tf.Tensor(-0.40089443, shape=(), dtype=float...   Puerto Rico   \n",
       "3      65326  ((tf.Tensor(0.07629065, shape=(), dtype=float3...   Puerto Rico   \n",
       "4      44303  ((tf.Tensor(-0.116008, shape=(), dtype=float32...   Puerto Rico   \n",
       "\n",
       "  Closest_City   Region  \n",
       "0    Vega Alta  NonCont  \n",
       "1    Vega Alta  NonCont  \n",
       "2    Vega Alta  NonCont  \n",
       "3    Vega Alta  NonCont  \n",
       "4    Vega Alta  NonCont  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(out_df['TweetText'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('noncont_embeddings.pkl', 'wb') as file:\n",
    "    pickle.dump(out_df, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
