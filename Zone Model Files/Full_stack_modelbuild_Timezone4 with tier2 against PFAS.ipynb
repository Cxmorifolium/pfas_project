{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6ecfb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv1D, Conv2D, GlobalMaxPooling1D, MaxPooling2D, Flatten, Dense, Input, Concatenate, Embedding, GlobalAveragePooling1D\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebd8c58",
   "metadata": {},
   "source": [
    "## Purpose:\n",
    "\n",
    "2 tier CNN\n",
    "\n",
    "First tier predicts timezone\n",
    "\n",
    "Second tier predicts state inside indicated timezone from tier 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "422feefd-4f92-4f4f-ab0f-412da12ba48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimizes class disparity while stil allowing some variation between tweets from different states\n",
    "def equalify(df, rstate):\n",
    "    vals = df['Closest_State'].unique()\n",
    "    samples = []\n",
    "    \n",
    "    for val in vals:\n",
    "        filter_df = df[df['Closest_State'] == val]\n",
    "        if len(filter_df) >= 1500:\n",
    "            sample = filter_df.sample(n=1500, replace = False, random_state = rstate)\n",
    "        else:\n",
    "            sample = filter_df\n",
    "        samples.append(sample)\n",
    "\n",
    "    combined = pd.concat(samples)\n",
    "    combined = combined.reset_index(drop = True)\n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bd8d1fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(374519, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa = pd.read_csv('All_US_Time_tweets.csv')\n",
    "dfa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "674a5bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('west_time_tweets.csv')\n",
    "df1 = equalify(df1, 100)\n",
    "\n",
    "df2 = pd.read_csv('central_time_tweets.csv')\n",
    "df2 = equalify(df2, 100)\n",
    "\n",
    "df3 = pd.read_csv('east_time_tweets.csv')\n",
    "df3 = equalify(df3, 100)\n",
    "\n",
    "df4 = pd.read_csv('mountain_time_tweets.csv')\n",
    "df4 = equalify(df4, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d83c7dda-e732-4e07-94ba-f9ddeafa4420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Closest_State\n",
       "New York                76393\n",
       "New Jersey              47047\n",
       "California              34634\n",
       "Georgia                 25966\n",
       "Florida                 20181\n",
       "Texas                   18330\n",
       "Maryland                18035\n",
       "Virginia                15679\n",
       "Ohio                    13774\n",
       "North Carolina          13328\n",
       "Illinois                 9478\n",
       "Michigan                 9456\n",
       "Pennsylvania             8949\n",
       "South Carolina           5648\n",
       "Conneticut               5549\n",
       "Tennessee                5295\n",
       "Massachusetts            4148\n",
       "Arizona                  4136\n",
       "Louisiana                4051\n",
       "Alabama                  3136\n",
       "Indiana                  2970\n",
       "Washington               2963\n",
       "Mississippi              2772\n",
       "District of Columbia     2595\n",
       "Missouri                 2568\n",
       "Nevada                   1806\n",
       "Minnesota                1567\n",
       "Kentucky                 1369\n",
       "Wisconsin                1324\n",
       "Oklahoma                 1259\n",
       "Rhode Island             1200\n",
       "Delaware                 1159\n",
       "Arkansas                 1158\n",
       "Oregon                   1007\n",
       "Colorado                  927\n",
       "Vermont                   924\n",
       "Kansas                    605\n",
       "Iowa                      484\n",
       "Maine                     455\n",
       "West Virginia             363\n",
       "Puerto Rico               348\n",
       "New Mexico                327\n",
       "Utah                      298\n",
       "Nebraska                  250\n",
       "Idaho                     226\n",
       "North Dakota              126\n",
       "New Hampshire             110\n",
       "South Dakota               94\n",
       "Montana                    27\n",
       "Wyoming                    25\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa['Closest_State'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27d0a189",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['TweetText'] = dfa['TweetText'].astype(str)\n",
    "df1['TweetText'] = df1['TweetText'].astype(str)\n",
    "df2['TweetText'] = df2['TweetText'].astype(str)\n",
    "df3['TweetText'] = df3['TweetText'].astype(str)\n",
    "df4['TweetText'] = df4['TweetText'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a4c620f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teach the tokenizer on all available text, then sample out the main dataset\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(dfa['TweetText'].tolist())\n",
    "\n",
    "dfa = equalify(dfa, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a093dd3c-149a-4a34-8f6b-f61a47b913bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = pd.get_dummies(dfa['Timezone'])\n",
    "dfa = dfa.join(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3da4fa04-8a94-4608-9374-2b234b77e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_onehot(df):\n",
    "    one_hot = pd.get_dummies(df['Closest_State'])\n",
    "    df = df.join(one_hot)\n",
    "    #df = df.drop('Closest_State', axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "33f069d1-4836-430f-9afd-e76b35035a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = make_onehot(df1)\n",
    "df2 = make_onehot(df2)\n",
    "df3 = make_onehot(df3)\n",
    "df4 = make_onehot(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "410d2e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = dfa[['TweetText','Timestamp']]\n",
    "y_data = dfa[dfa['Timezone'].unique()]\n",
    "\n",
    "x_dat1 = df1[['TweetText','Timestamp']]\n",
    "y_dat1 = df1[df1['Closest_State'].unique()]\n",
    "\n",
    "x_dat2 = df2[['TweetText','Timestamp']]\n",
    "y_dat2 = df2[df2['Closest_State'].unique()]\n",
    "\n",
    "x_dat3 = df3[['TweetText','Timestamp']]\n",
    "y_dat3 = df3[df3['Closest_State'].unique()]\n",
    "\n",
    "x_dat4 = df4[['TweetText','Timestamp']]\n",
    "y_dat4 = df4[df4['Closest_State'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c68310a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_traina, x_testa, y_traina, y_testa = train_test_split(x_data, y_data, test_size = 0.25, random_state = 40)\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(x_dat1, y_dat1, test_size = 0.25, random_state = 40)\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x_dat2, y_dat2, test_size = 0.25, random_state = 40)\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x_dat3, y_dat3, test_size = 0.25, random_state = 40)\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(x_dat4, y_dat4, test_size = 0.25, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39d87a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    54565.000000\n",
       "mean        12.062329\n",
       "std          7.782837\n",
       "min          1.000000\n",
       "1%           2.000000\n",
       "50%         11.000000\n",
       "99%         28.000000\n",
       "max        647.000000\n",
       "Name: TweetText, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data[\"TweetText\"].str.split(\" \").str.len().describe(percentiles=[0.01, 0.5, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb7071a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmax_length = 29"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f295881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq(x_train, x_test):\n",
    "    train_sequences = tokenizer.texts_to_sequences(x_train['TweetText'].tolist())\n",
    "    test_sequences = tokenizer.texts_to_sequences(x_test['TweetText'].tolist())\n",
    "    \n",
    "    train_seq = pad_sequences(train_sequences, maxlen = tmax_length, padding = 'post', truncating = 'post')\n",
    "    test_seq = pad_sequences(test_sequences, maxlen = tmax_length, padding = 'post', truncating = 'post')\n",
    "\n",
    "    return train_seq, test_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb58e434-9b4c-46c2-a6c9-7befe9a19ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seqa, test_seqa = get_seq(x_traina, x_testa)\n",
    "train_seq1, test_seq1 = get_seq(x_train1, x_test1)\n",
    "train_seq2, test_seq2 = get_seq(x_train2, x_test2)\n",
    "train_seq3, test_seq3 = get_seq(x_train3, x_test3)\n",
    "train_seq4, test_seq4 = get_seq(x_train4, x_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cc5c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.index_word) + 1\n",
    "embedding_dim = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb334c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_traina = x_traina['Timestamp']\n",
    "timestamps_testa = x_testa['Timestamp']\n",
    "\n",
    "timestamps_train1 = x_train1['Timestamp']\n",
    "timestamps_test1 = x_test1['Timestamp']\n",
    "\n",
    "timestamps_train2 = x_train2['Timestamp']\n",
    "timestamps_test2 = x_test2['Timestamp']\n",
    "\n",
    "timestamps_train3 = x_train3['Timestamp']\n",
    "timestamps_test3 = x_test3['Timestamp']\n",
    "\n",
    "timestamps_train4 = x_train4['Timestamp']\n",
    "timestamps_test4 = x_test4['Timestamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "406d47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seq = Input(shape = (tmax_length,), name = 'Input Sequence')\n",
    "input_time = Input(shape = (1,), name = \"Input Timestamp\")\n",
    "\n",
    "embed = Embedding(input_dim = vocab_size, output_dim = embedding_dim, input_length = tmax_length)(input_seq)\n",
    "convol = Conv1D(filters = 128, kernel_size = 3, activation = 'relu')(embed)\n",
    "maxpool = GlobalAveragePooling1D()(convol)\n",
    "\n",
    "concat = Concatenate()([maxpool, input_time])\n",
    "dense1 = Dense(50, activation = 'relu')(concat)\n",
    "dense2 = Dense(25, activation = 'relu')(dense1)\n",
    "dense3 = Dense(15, activation = 'relu')(dense2)\n",
    "output = Dense(len(dfa['Timezone'].unique()), activation = 'sigmoid')(dense3)\n",
    "\n",
    "modela = Model(inputs = [input_seq, input_time], outputs = output)\n",
    "modela.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "output = Dense(len(df1['Closest_State'].unique()), activation = 'sigmoid')(dense3)\n",
    "\n",
    "model1 = Model(inputs = [input_seq, input_time], outputs = output)\n",
    "model1.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "output = Dense(len(df2['Closest_State'].unique()), activation = 'sigmoid')(dense3)\n",
    "\n",
    "model2 = Model(inputs = [input_seq, input_time], outputs = output)\n",
    "model2.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "output = Dense(len(df3['Closest_State'].unique()), activation = 'sigmoid')(dense3)\n",
    "\n",
    "model3 = Model(inputs = [input_seq, input_time], outputs = output)\n",
    "model3.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "output = Dense(len(df4['Closest_State'].unique()), activation = 'sigmoid')(dense3)\n",
    "\n",
    "model4 = Model(inputs = [input_seq, input_time], outputs = output)\n",
    "model4.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83fa183e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 157ms/step - accuracy: 0.3696 - loss: 108.0358 - val_accuracy: 0.5162 - val_loss: 31.8042\n",
      "Epoch 2/3\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 157ms/step - accuracy: 0.3863 - loss: 39.3043 - val_accuracy: 0.5147 - val_loss: 25.1940\n",
      "Epoch 3/3\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 157ms/step - accuracy: 0.4030 - loss: 32.2509 - val_accuracy: 0.3367 - val_loss: 39.8081\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x26923a9e8d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modela.fit([train_seqa, timestamps_traina], y_traina, epochs = 3, batch_size = 100, validation_data = ([test_seqa, timestamps_testa], y_testa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "056d5e04-7528-434c-804c-0eedc2fd72b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 156ms/step - accuracy: 0.2631 - loss: 490.3237 - val_accuracy: 0.2680 - val_loss: 1.3889\n",
      "Epoch 2/3\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 155ms/step - accuracy: 0.2735 - loss: 1.3937 - val_accuracy: 0.2629 - val_loss: 1.3859\n",
      "Epoch 3/3\n",
      "\u001b[1m83/83\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 155ms/step - accuracy: 0.2791 - loss: 1.3847 - val_accuracy: 0.2629 - val_loss: 1.3843\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2692948b230>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit([train_seq1, timestamps_train1], y_train1, epochs = 3, batch_size = 50, validation_data = ([test_seq1, timestamps_test1], y_test1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f4139fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 156ms/step - accuracy: 0.0839 - loss: 3.0292 - val_accuracy: 0.0830 - val_loss: 2.7148\n",
      "Epoch 2/3\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 155ms/step - accuracy: 0.0890 - loss: 2.7029 - val_accuracy: 0.0832 - val_loss: 2.6806\n",
      "Epoch 3/3\n",
      "\u001b[1m260/260\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 155ms/step - accuracy: 0.0907 - loss: 2.6699 - val_accuracy: 0.0835 - val_loss: 2.6597\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2692c2be090>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit([train_seq2, timestamps_train2], y_train2, epochs = 3, batch_size = 50, validation_data = ([test_seq2, timestamps_test2], y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91104fd1-9415-4c80-acca-6ae3ae8c43d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 158ms/step - accuracy: 0.0538 - loss: 3.1285 - val_accuracy: 0.0484 - val_loss: 3.1045\n",
      "Epoch 2/3\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 157ms/step - accuracy: 0.0543 - loss: 3.1080 - val_accuracy: 0.0469 - val_loss: 3.0858\n",
      "Epoch 3/3\n",
      "\u001b[1m214/214\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 157ms/step - accuracy: 0.0548 - loss: 3.0831 - val_accuracy: 0.0467 - val_loss: 3.0736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x2692f53d5b0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit([train_seq3, timestamps_train3], y_train3, epochs = 3, batch_size = 100, validation_data = ([test_seq3, timestamps_test3], y_test3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb477730-26cd-4e55-9348-d26827004b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 159ms/step - accuracy: 0.3851 - loss: 1.9356 - val_accuracy: 0.4550 - val_loss: 1.9063\n",
      "Epoch 2/3\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 154ms/step - accuracy: 0.4174 - loss: 2.0989 - val_accuracy: 0.4550 - val_loss: 1.8695\n",
      "Epoch 3/3\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 155ms/step - accuracy: 0.4620 - loss: 1.8547 - val_accuracy: 0.4550 - val_loss: 1.8355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x269267ab230>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit([train_seq4, timestamps_train4], y_train4, epochs = 3, batch_size = 50, validation_data = ([test_seq4, timestamps_test4], y_test4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9afb98e9-ef09-4784-870b-0f388abfa3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getpred_seq(x_text):\n",
    "    sequences = tokenizer.texts_to_sequences(x_text['TweetText'].tolist())\n",
    "    seq = pad_sequences(sequences, maxlen = 29, padding = 'post', truncating = 'post')\n",
    "\n",
    "    return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8aed205-a8b1-4388-aae7-d86ab0bca8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pf =pd.read_csv('All_US_Time_tweets.csv')\n",
    "# random samples with different state to get different from what was trained on\n",
    "df_pf = equalify(df_pf, 300)\n",
    "df_pf['TweetText'] = df_pf['TweetText'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "976a356b-b30f-4a26-a91a-b91305881b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "xp_data = df_pf[['TweetText','Timestamp']]\n",
    "pred_time = xp_data[['Timestamp']]\n",
    "ypt_data = df_pf[['Timezone']]\n",
    "yps_data = df_pf[['Closest_State']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "68df2397-6760-4963-97cb-25660a8ced93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_seq = getpred_seq(xp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "781383fd-8303-42f0-ab24-b2d2e29b7261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Central', 'Mountain', 'West', 'East'], dtype='object')\n",
      "Index(['California', 'Nevada', 'Oregon', 'Washington'], dtype='object')\n",
      "Index(['Alabama', 'Arkansas', 'Illinois', 'Iowa', 'Kansas', 'Louisiana',\n",
      "       'Minnesota', 'Mississippi', 'Missouri', 'Nebraska', 'North Dakota',\n",
      "       'Oklahoma', 'South Dakota', 'Tennessee', 'Texas', 'Wisconsin'],\n",
      "      dtype='object')\n",
      "Index(['Conneticut', 'Delaware', 'District of Columbia', 'Florida', 'Georgia',\n",
      "       'Indiana', 'Kentucky', 'Maine', 'Maryland', 'Massachusetts', 'Michigan',\n",
      "       'New Hampshire', 'New Jersey', 'New York', 'North Carolina', 'Ohio',\n",
      "       'Pennsylvania', 'Puerto Rico', 'Rhode Island', 'South Carolina',\n",
      "       'Vermont', 'Virginia', 'West Virginia'],\n",
      "      dtype='object')\n",
      "Index(['Arizona', 'Colorado', 'Idaho', 'Montana', 'New Mexico', 'Utah',\n",
      "       'Wyoming'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(y_traina.columns)\n",
    "print(y_train1.columns)\n",
    "print(y_train2.columns)\n",
    "print(y_train3.columns)\n",
    "print(y_train4.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e5adb744-25ee-4479-9515-9ea7572a3c0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>TweetText</th>\n",
       "      <th>Closest_State</th>\n",
       "      <th>Closest_City</th>\n",
       "      <th>Region</th>\n",
       "      <th>Timezone</th>\n",
       "      <th>Subtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69662</td>\n",
       "      <td>nowwatching my fav show flip this house</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Tuskegee</td>\n",
       "      <td>Deep South</td>\n",
       "      <td>Central</td>\n",
       "      <td>South Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25417</td>\n",
       "      <td>my opponent brother is running the elections</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>Deep South</td>\n",
       "      <td>Central</td>\n",
       "      <td>South Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3566</td>\n",
       "      <td>rt  what to wear tonight help</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>Deep South</td>\n",
       "      <td>Central</td>\n",
       "      <td>South Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>72235</td>\n",
       "      <td>rt  why dont people know what to wear when its...</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Homewood</td>\n",
       "      <td>Deep South</td>\n",
       "      <td>Central</td>\n",
       "      <td>South Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82911</td>\n",
       "      <td>sooo say ure havin a shitty flight huh jusaskin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>Deep South</td>\n",
       "      <td>Central</td>\n",
       "      <td>South Central</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Timestamp                                          TweetText Closest_State  \\\n",
       "0      69662            nowwatching my fav show flip this house       Alabama   \n",
       "1      25417       my opponent brother is running the elections       Alabama   \n",
       "2       3566                     rt  what to wear tonight help        Alabama   \n",
       "3      72235  rt  why dont people know what to wear when its...       Alabama   \n",
       "4      82911    sooo say ure havin a shitty flight huh jusaskin       Alabama   \n",
       "\n",
       "  Closest_City      Region Timezone        Subtime  \n",
       "0     Tuskegee  Deep South  Central  South Central  \n",
       "1   Huntsville  Deep South  Central  South Central  \n",
       "2   Birmingham  Deep South  Central  South Central  \n",
       "3     Homewood  Deep South  Central  South Central  \n",
       "4   Montgomery  Deep South  Central  South Central  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11a45341-f9d9-4090-8197-a1ddfba6e116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(vals):\n",
    "    tp = vals['TP']\n",
    "    tn = vals['TN']\n",
    "    fp = vals['FP']\n",
    "    fn = vals['FN']\n",
    "\n",
    "    prec = tp/(tp + fp)\n",
    "    rec = tp/(tp + fn)\n",
    "\n",
    "    f1 = 2*((prec*rec)/(prec+rec))\n",
    "\n",
    "    print('Precision: ' + str(prec))\n",
    "    print('Recall: ' + str(rec))\n",
    "    print('F1: ' + str(f1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "12b3fe0d-afcb-4f81-be27-0a4e66273b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "run_list = ['North Carolina','Colorado','Wisconsin', 'California']\n",
    "run_zone = ['East','Mountain','Central','West']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0480b9bf-3432-45d8-ace6-f2e39222d79d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54560</th>\n",
       "      <td>Mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54561</th>\n",
       "      <td>Mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54562</th>\n",
       "      <td>Mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54563</th>\n",
       "      <td>Mountain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54564</th>\n",
       "      <td>Mountain</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54565 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Timezone\n",
       "0       Central\n",
       "1       Central\n",
       "2       Central\n",
       "3       Central\n",
       "4       Central\n",
       "...         ...\n",
       "54560  Mountain\n",
       "54561  Mountain\n",
       "54562  Mountain\n",
       "54563  Mountain\n",
       "54564  Mountain\n",
       "\n",
       "[54565 rows x 1 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ypt_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0969aa8-4191-4aab-b771-1446b5a62307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows processed: 54500/54565\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "imax = df_pf.shape[0]\n",
    "#imax = i + 50\n",
    "\n",
    "eval_state = 'North Carolina'\n",
    "eval_zone = 'East'\n",
    "\n",
    "tzon = y_traina.columns\n",
    "west_states = y_train1.columns\n",
    "cent_states = y_train2.columns\n",
    "east_states = y_train3.columns\n",
    "mount_states = y_train4.columns\n",
    "\n",
    "z_tp = 0\n",
    "z_tn = 0\n",
    "z_fp = 0\n",
    "z_fn = 0\n",
    "\n",
    "s_tp = 0\n",
    "s_tn = 0\n",
    "s_fp = 0\n",
    "s_fn = 0\n",
    "\n",
    "while i < imax:\n",
    "    text = pred_seq[i:i+1]\n",
    "    time = pred_time['Timestamp'][i:i+1]\n",
    "    target_zone = ypt_data['Timezone'][i]\n",
    "    target_state = yps_data['Closest_State'][i]\n",
    "\n",
    "    time_pred = modela.predict([text,time], verbose = 0)\n",
    "    zone = tzon[np.argmax(time_pred[0])]\n",
    "    \n",
    "\n",
    "    if zone == 'West':\n",
    "        pred = model1.predict([text,time], verbose = 0)\n",
    "        state_pred = west_states[np.argmax(pred[0])]\n",
    "\n",
    "    elif zone == 'Central':\n",
    "        pred = model2.predict([text,time], verbose = 0)\n",
    "        state_pred = cent_states[np.argmax(pred[0])]\n",
    "\n",
    "    elif zone == 'East':\n",
    "        pred = model3.predict([text,time], verbose = 0)\n",
    "        state_pred = east_states[np.argmax(pred[0])]\n",
    "\n",
    "    elif zone == 'Mountain':\n",
    "        pred = model4.predict([text,time], verbose = 0)\n",
    "        state_pred = mount_states[np.argmax(pred[0])]\n",
    "\n",
    "    else: \n",
    "        print('Timezone has no prediction')\n",
    "        i == imax + 1\n",
    "\n",
    "    #Timezone scoring\n",
    "    if eval_zone == zone and target_zone == zone:\n",
    "        z_tp += 1\n",
    "    elif eval_zone != zone and target_zone == zone:\n",
    "        z_tn += 1\n",
    "    elif eval_zone == zone and target_zone != zone:\n",
    "        z_fp += 1\n",
    "    elif eval_zone != zone and target_zone != zone:\n",
    "        z_fn += 1\n",
    "\n",
    "    # State scoring\n",
    "    if eval_state == state_pred and target_state == state_pred:\n",
    "        s_tp += 1\n",
    "    elif eval_state != state_pred and target_state == state_pred:\n",
    "        s_tn += 1\n",
    "    elif eval_state == state_pred and target_state != state_pred:\n",
    "        s_fp += 1\n",
    "    elif eval_state != state_pred and target_state != state_pred:\n",
    "        s_fn += 1\n",
    "\n",
    "    # print('Zone Eval: ' + eval_zone)\n",
    "    # print('Zone Actual: ' + target_zone)\n",
    "    # print('Zone Prediction: ' + zone)\n",
    "    # print('State Eval: ' + eval_state)\n",
    "    # print('State Actual: ' + target_state)\n",
    "    # print('State Prediciton: ' + state_pred)\n",
    "    # print('')\n",
    "    if i % 500 == 0:\n",
    "        clear_output()\n",
    "        print('Rows processed: ' + str(i) + '/' + str(imax))\n",
    "\n",
    "    i += 1\n",
    "\n",
    "zone_perf = {'TP': z_tp, 'TN': z_tn, 'FP': z_fp, 'FN': z_fn}\n",
    "state_perf = {'TP': s_tp, 'TN': s_tn, 'FP': s_fp, 'FN': s_fn}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0f52199-8fcc-410d-8365-462891c7077b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'TP': 32, 'TN': 5497, 'FP': 22, 'FN': 49014}\n",
      "{'TP': 0, 'TN': 1497, 'FP': 0, 'FN': 53068}\n"
     ]
    }
   ],
   "source": [
    "print(zone_perf)\n",
    "print(state_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94ab51fc-42f6-495a-b090-592a10763542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.5925925925925926\n",
      "Recall: 0.0006524487216082861\n",
      "F1: 0.0013034623217922606\n"
     ]
    }
   ],
   "source": [
    "get_scores(zone_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f195640-0cac-4119-9dfc-295c391491b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
